{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Note: \n",
    "The data loaded in below was stored locally and is not in the GitHub repo in order to keep the size of the repo down. The json files created are relatively small and are in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Libraries.\n",
    "import matplotlib, matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "# Setup.\n",
    "% matplotlib inline\n",
    "\n",
    "# Paths.\n",
    "path_data = '../../../data/gatecount_%d/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>locationid</th>\n",
       "      <th>entries</th>\n",
       "      <th>servicedate</th>\n",
       "      <th>servicetime_fraction</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1002</td>\n",
       "      <td> 0</td>\n",
       "      <td> 2013-01-01 00:00:00</td>\n",
       "      <td> 3.00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1002</td>\n",
       "      <td> 1</td>\n",
       "      <td> 2013-01-01 00:00:00</td>\n",
       "      <td> 5.00</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2</td>\n",
       "      <td> 1002</td>\n",
       "      <td> 2</td>\n",
       "      <td> 2013-01-01 00:00:00</td>\n",
       "      <td> 5.25</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 3</td>\n",
       "      <td> 1002</td>\n",
       "      <td> 3</td>\n",
       "      <td> 2013-01-01 00:00:00</td>\n",
       "      <td> 5.50</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 4</td>\n",
       "      <td> 1002</td>\n",
       "      <td> 6</td>\n",
       "      <td> 2013-01-01 00:00:00</td>\n",
       "      <td> 5.75</td>\n",
       "      <td> 1</td>\n",
       "      <td> 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  locationid  entries          servicedate  servicetime_fraction  \\\n",
       "0           0        1002        0  2013-01-01 00:00:00                  3.00   \n",
       "1           1        1002        1  2013-01-01 00:00:00                  5.00   \n",
       "2           2        1002        2  2013-01-01 00:00:00                  5.25   \n",
       "3           3        1002        3  2013-01-01 00:00:00                  5.50   \n",
       "4           4        1002        6  2013-01-01 00:00:00                  5.75   \n",
       "\n",
       "   weekday  month  \n",
       "0        1      1  \n",
       "1        1      1  \n",
       "2        1      1  \n",
       "3        1      1  \n",
       "4        1      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gate_1315=pd.read_csv('../../../data/gatecounts_edit_1315.csv')\n",
    "gate_1315.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py:1130: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = self._reader.read(nrows)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationid</th>\n",
       "      <th>service_day</th>\n",
       "      <th>entries</th>\n",
       "      <th>name</th>\n",
       "      <th>line_1</th>\n",
       "      <th>line_2</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>service_datetime</th>\n",
       "      <th>fog</th>\n",
       "      <th>...</th>\n",
       "      <th>entries_weeks_ago_1</th>\n",
       "      <th>entries_weeks_ago_2</th>\n",
       "      <th>entries_weeks_ago_3</th>\n",
       "      <th>rain_predict</th>\n",
       "      <th>rain_fall_predict</th>\n",
       "      <th>snow_predict</th>\n",
       "      <th>snow_fall_predict</th>\n",
       "      <th>snow_accum</th>\n",
       "      <th>snow_accum_predict</th>\n",
       "      <th>dist_to_center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-01 00:00:00</td>\n",
       "      <td> 1892</td>\n",
       "      <td> Andrew Square</td>\n",
       "      <td> Red</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 42.32955</td>\n",
       "      <td>-71.05696</td>\n",
       "      <td> 2013-01-01 03:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3.404767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-02 00:00:00</td>\n",
       "      <td> 5134</td>\n",
       "      <td> Andrew Square</td>\n",
       "      <td> Red</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 42.32955</td>\n",
       "      <td>-71.05696</td>\n",
       "      <td> 2013-01-02 04:45:00</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3.404767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-03 00:00:00</td>\n",
       "      <td> 5733</td>\n",
       "      <td> Andrew Square</td>\n",
       "      <td> Red</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 42.32955</td>\n",
       "      <td>-71.05696</td>\n",
       "      <td> 2013-01-03 05:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3.404767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-04 00:00:00</td>\n",
       "      <td> 6125</td>\n",
       "      <td> Andrew Square</td>\n",
       "      <td> Red</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 42.32955</td>\n",
       "      <td>-71.05696</td>\n",
       "      <td> 2013-01-04 05:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3.404767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-05 00:00:00</td>\n",
       "      <td> 3410</td>\n",
       "      <td> Andrew Square</td>\n",
       "      <td> Red</td>\n",
       "      <td> NaN</td>\n",
       "      <td> 42.32955</td>\n",
       "      <td>-71.05696</td>\n",
       "      <td> 2013-01-05 04:15:00</td>\n",
       "      <td> 0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "      <td> 3.404767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationid          service_day  entries           name line_1 line_2  \\\n",
       "0        1002  2013-01-01 00:00:00     1892  Andrew Square    Red    NaN   \n",
       "1        1002  2013-01-02 00:00:00     5134  Andrew Square    Red    NaN   \n",
       "2        1002  2013-01-03 00:00:00     5733  Andrew Square    Red    NaN   \n",
       "3        1002  2013-01-04 00:00:00     6125  Andrew Square    Red    NaN   \n",
       "4        1002  2013-01-05 00:00:00     3410  Andrew Square    Red    NaN   \n",
       "\n",
       "        lat       lon     service_datetime  fog ...   entries_weeks_ago_1  \\\n",
       "0  42.32955 -71.05696  2013-01-01 03:00:00    0 ...                   NaN   \n",
       "1  42.32955 -71.05696  2013-01-02 04:45:00    0 ...                   NaN   \n",
       "2  42.32955 -71.05696  2013-01-03 05:00:00    0 ...                   NaN   \n",
       "3  42.32955 -71.05696  2013-01-04 05:00:00    0 ...                   NaN   \n",
       "4  42.32955 -71.05696  2013-01-05 04:15:00    0 ...                   NaN   \n",
       "\n",
       "   entries_weeks_ago_2  entries_weeks_ago_3  rain_predict  rain_fall_predict  \\\n",
       "0                  NaN                  NaN             0                  0   \n",
       "1                  NaN                  NaN             0                  0   \n",
       "2                  NaN                  NaN             0                  0   \n",
       "3                  NaN                  NaN             0                  0   \n",
       "4                  NaN                  NaN             0                  0   \n",
       "\n",
       "   snow_predict  snow_fall_predict  snow_accum  snow_accum_predict  \\\n",
       "0             0                  0           0                   0   \n",
       "1             0                  0           0                   0   \n",
       "2             0                  0           0                   0   \n",
       "3             0                  0           0                   0   \n",
       "4             1                  0           0                   0   \n",
       "\n",
       "   dist_to_center  \n",
       "0        3.404767  \n",
       "1        3.404767  \n",
       "2        3.404767  \n",
       "3        3.404767  \n",
       "4        3.404767  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbta_daily=pd.read_csv('../../../data/mbta_daily.csv')\n",
    "mbta_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>locationid</th>\n",
       "      <th>service_day</th>\n",
       "      <th>snow</th>\n",
       "      <th>snow_fall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-01 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-02 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-03 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-04 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 2013-01-05 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   locationid          service_day  snow  snow_fall\n",
       "0        1002  2013-01-01 00:00:00     0          0\n",
       "1        1002  2013-01-02 00:00:00     0          0\n",
       "2        1002  2013-01-03 00:00:00     0          0\n",
       "3        1002  2013-01-04 00:00:00     0          0\n",
       "4        1002  2013-01-05 00:00:00     0          0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbta_daily['month']=map(month_col,mbta_daily['service_day'].values)\n",
    "\n",
    "mbta_daily=mbta_daily[['locationid','service_day','snow','snow_fall']]\n",
    "mbta_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_day</th>\n",
       "      <th>snow</th>\n",
       "      <th>snow_fall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2013-01-01 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2013-01-02 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2013-01-03 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2013-01-04 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2013-01-05 00:00:00</td>\n",
       "      <td> 0</td>\n",
       "      <td> 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           service_day  snow  snow_fall\n",
       "0  2013-01-01 00:00:00     0          0\n",
       "1  2013-01-02 00:00:00     0          0\n",
       "2  2013-01-03 00:00:00     0          0\n",
       "3  2013-01-04 00:00:00     0          0\n",
       "4  2013-01-05 00:00:00     0          0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow_daily=mbta_daily.groupby('service_day').agg(np.mean).reset_index()\n",
    "snow_daily=snow_daily[['service_day','snow','snow_fall']]\n",
    "snow_daily.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Determining snow bins\n",
    "\n",
    "It's difficult to create equal-length bins, especially when approximately 75% of snowfall is 0-2 inches. The rest of the bins are as close to equally sized as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD8CAYAAACxUoU3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAADlpJREFUeJzt3X+snYVdx/H3Nt1AwtpBLFt7sbWDL63/zOEzowjtXLaY\n",
       "YaQaNSBG2WR1DXTEgsTBwqKiIQE1c7P7g66JxhEDy2IkAks2JVezDeVRE+OS5isUGN4IlwtllF+T\n",
       "H9c/zqm9dr3nnEvPuc/93r5f//Te+9DTT0vzvs/58fSAJEmSJEmSJEmSJEmSJElaRm8adDAifgL4\n",
       "LWAWeADYAGwE1gB7MnNu4gslSbx5yPHLgD/IzGuAXwY+mJm7gf3AzkmPkyT1fN+Q458BPh0Rc8Bp\n",
       "wOP9r88A6yc5TJJ01LBYnw3cnJmPRMTXgLP6X5+iF+zjatv2ReDU8UyUpJPGdNM071/yz4qIH46I\n",
       "L0fEn0fExyLimojYGxF3RMTpi/28tm3nT2RtF9q2bbvesFTVNlfbC/U2V9sLbj7mdhdt58Az68x8\n",
       "BPjFsS+SJC3JsCcYJUkrgLGWpAKMtSQVYKwlqQBjLUkFGGtJKsBYS1IBxlqSCjDWklSAsZakAoy1\n",
       "JBVgrCWpAGMtSQUYa0kqwFhLUgHGWpIKMNaSVICxlqQCjLUkFTDwPRgj4j3Ap4DHgXngCWATsAbY\n",
       "k5lzi/3cH/u535ke38zJ+8Pbv3bews3fmT34Hw/905eu7nKTJB0xMNbAU8AG4HXg34FtmXlJRLwf\n",
       "2AncsthPfNe5P7ltXCOXwyvAu87l/za//tqrz3Y4R5L+n2EPg+wCbsrMy4CfphdvgBlg/SSHSZKO\n",
       "GnZmfQrwTP/jZ4GN/Y+n6AV71dqyed32fW3bdr1jiK3tyt+4ULW9UG9ztb3g5pEMi/XngFsjYg54\n",
       "AHglIvYCa+mdda9aBw7OTjdNs6PrHYO0bds2TdN0vWNU1fZCvc3V9oKbj7nd+cWODYx1Zj4O/Mq4\n",
       "B0mSlsaX7klSAcZakgow1pJUgLGWpAKMtSQVYKwlqQBjLUkFGGtJKsBYS1IBxlqSCjDWklSAsZak\n",
       "Aoy1JBVgrCWpAGMtSQUYa0kqwFhLUgHGWpIKMNaSVMDA92CMiKuA9wFvBX4K+DNgE7AG2JOZc5Me\n",
       "KEkacmadmZ/PzI8CR944d1tm7gb2AzuXYZ8kiREeBomILfTOwB8FZvtfngHWT26WJGmhgQ+D9F0N\n",
       "3EYv1Gf2vzZFL9ir1pbN67bva9u26x1DbG1X/saFqu2Fepur7QU3j2SUWG/NzG8DRMT9EbEXWAvs\n",
       "muiyjh04ODvdNM2OrncM0rZt2zRN0/WOUVXbC/U2V9sLbj7mducXOzY01pn5wQUff3ZcoyRJo/Ol\n",
       "e5JUgLGWpAKMtSQVYKwlqQBjLUkFGGtJKsBYS1IBxlqSCjDWklSAsZakAoy1JBVgrCWpAGMtSQUY\n",
       "a0kqwFhLUgHGWpIKMNaSVICxlqQCjLUkFTDwPRgjYhNwE/Ad4BDwErAJWAPsycy5Ce+TJDH8zPo6\n",
       "4GF672b+ILAtM3cD+4GdE94mSeob9u7m7wa+AHwL+CrwUP/rM8D6Ce7q3JbN67bva9u26x1DbG1X\n",
       "/saFqu2Fepur7QU3j2RYrJ8ADmfmqxHxInBm/+tT9IK9ah04ODvdNM2OrncM0rZt2zRN0/WOUVXb\n",
       "C/U2V9sLbj7mducXOzYs1rcCt0TEc8AXgR+MiL30HhbZNb6JkqRBBsY6Mw8Aly7TFknSInzpniQV\n",
       "YKwlqQBjLUkFGGtJKsBYS1IBxlqSCjDWklSAsZakAoy1JBVgrCWpAGMtSQUYa0kqwFhLUgHGWpIK\n",
       "MNaSVICxlqQCjLUkFWCsJamAgW/rFREbgb8B/g34b+AZYBOwBtiTmXOTHihJGn5mfRG9SM8D3wC2\n",
       "ZeZuYD+wc8LbJEl9w97d/J+BrwKzwN8BD/e/PgOsn+AuSdICw2L9XuCbmTkfES9yNNBT9IK9am3Z\n",
       "vG77vrZtu94xxNZ25W9cqNpeqLe52l5w80iGxfo/gdsiYhb4a+C0iNgLrAV2TXpclw4cnJ1ummZH\n",
       "1zsGadu2bZqm6XrHqKrthXqbq+0FNx9zu/OLHRsY68z8V+DScQ+SJC2NL92TpAKMtSQVYKwlqQBj\n",
       "LUkFGGtJKsBYS1IBxlqSCjDWklSAsZakAoy1JBVgrCWpAGMtSQUYa0kqwFhLUgHGWpIKMNaSVICx\n",
       "lqQCjLUkFWCsJamAYW+YC0BE3AHcDfwQsBFYA+zJzLkJbpMk9Q09s46Ia4Hn+p9elJm7gf3AzkkO\n",
       "kyQdNTDWEXEJcAh4AHgLMNs/NAOsn+w0SdIRwx4GuZxerM/rf364/+MUvWCvWls2r9u+r23brncM\n",
       "sbVd+RsXqrYX6m2uthfcPJKBsc7MywAi4grgJeCdEbEXWAvsmvy87hw4ODvdNM2OrncM0rZt2zRN\n",
       "0/WOUVXbC/U2V9sLbj7mducXOzbSE4yZ+RfjmyNJWipfuidJBRhrSSrAWEtSAcZakgow1pJUgLGW\n",
       "pAKMtSQVYKwlqQBjLUkFGGtJKsBYS1IBxlqSCjDWklSAsZakAoy1JBVgrCWpAGMtSQUYa0kqwFhL\n",
       "UgED34MxIs4Ffh+YA1pgHbARWAPsycy5iS+UJA09s3478EngWuBXgQszczewH9g54W2SpL6Bsc7M\n",
       "fwFeAf4WuB94qn9oBlg/2WmSpCOGPQzyXuCxzPyZiPgyR+M+RS/Yq9aWzeu272vbtusdQ2xtV/7G\n",
       "harthXqbq+0FN49kYKz7x2+PiP8CHgJmImIvsBbYNelxXTpwcHa6aZodXe8YpG3btmmapusdo6q2\n",
       "F+ptrrYX3HzM7c4vdmxgrDPzQeCXxj1IkrQ0vnRPkgow1pJUgLGWpAKMtSQVYKwlqQBjLUkFGGtJ\n",
       "KsBYS1IBxlqSCjDWklSAsZakAoy1JBVgrCWpAGMtSQUYa0kqwFhLUgHGWpIKMNaSVICxlqQChr27\n",
       "+QXAx4HDwJPAS8AmYA2wJzPnJj1QkjT8zHotcFVm7gYuBC7qf7wf2DnpcZKknoGxzsx7gRcj4kbg\n",
       "DuCp/qEZYP2Et0mS+oY9DHI68Bl6of4H4Bf6h6boBXvV2rJ53fZ9bdt2vWOIre3K37hQtb1Qb3O1\n",
       "veDmkQyMNb1QnwN8FPh14P6I2Evv4ZFdE97WqQMHZ6ebptnR9Y5B2rZtm6Zput4xqmp7od7manvB\n",
       "zcfc7vxixwbGOjOvHPcYSdLS+dI9SSrAWEtSAcZakgow1pJUgLGWpAKMtSQVYKwlqQBjLUkFGGtJ\n",
       "KsBYS1IBxlqSCjDWklSAsZakAoy1JBVgrCWpAGMtSQUYa0kqwFhLUgHGWpIKGPaGuQBExDnAXZl5\n",
       "fkRcD2wE1gB7MnNukgMlSSOcWUfEWcCVwPMR8TbgoszcDewHdk54nySJEc6sM/NJ4IaIuA84A5jt\n",
       "H5oB1k9wW6e2bF63fV/btl3vGGJru/I3LlRtL9TbXG0vuHkkIz0MssAscGb/4yl6wV6VDhycnW6a\n",
       "ZkfXOwZp27Ztmqbpeseoqu2Fepur7QU3H3O784sdW0qs5zPztYi4PyL2AmuBXSe8boWan38deo/N\n",
       "r1iPPfbYWxm+8XHg9WWYI2mCRo51Zl7c//Gzk5uzcrz8/DOnXnDpLY+ecvqZw//jjuy972k+8LHb\n",
       "H13s+MuHn+Ybd96wCXhs2UZJmoilPgxyUjnl9DP5gbev63qGJPk6a0mqwFhLUgHGWpIKMNaSVICx\n",
       "lqQCjLUkFWCsJakAX2e9ivWvwtzQ9Y4jRrzi8ni8ClMnPWO9ir38/CEuuPSWr6+UqzCHXXF5PF6F\n",
       "KfUY61XOqzBXjDcDZ0/6FzmBey+j8l5OR4y1tDzOXo5/a+aN3HsZlfdyumWspWXivRydCF8NIkkF\n",
       "GGtJKsCHQSSdTMbyRO8yPJH7PYy1pJPJWJ7oneQTuYsx1pJOKlWf6F1yrCNiA/BHwDPAtzLz82Nf\n",
       "JfV1fRXmGO/urpgrSVXTGzmz/k3gTzPzgYi4JyJuz8xXxz1Mgu6vwhzX3d1nn3hoDGt0MnsjsX4n\n",
       "vauYAA4Ba4Cnx7ZoBXn5cO3f1ndfOMSbuh5xgr77wiFOOe0dXc8Yi+p/n/r7x34PYZmfrNuwsv8/\n",
       "TC165I3E+tv0nk2dAc6gF+xjTf/u5VPb38BtrxyXf+JDXU84ced3PWAMVsPvAVbN7+P6D319Ejfb\n",
       "tu2jk7jdgqYXO7DkE6+IOAv4E+Aw8GBm7j+BYZIkSZIkSZIkSZIKGesruypeMBMRFwAfp/eE6ZOZ\n",
       "eXPHk0YWEXcAd2fmnV1vGSQiNgE3Ad8BDlX4M46I9wCfovcy1fnM/O2OJw0UEecAd2Xm+RFxPb2X\n",
       "wq0B9mTmXLfrvtcxez8H/A+91619MjMf6Xbd8S3c3P/8R4F9mfm+5fj1x/2v7h25YOZq4GcjosLl\n",
       "7GuBqzJzN3Bh12NGFRHX0vsGM9/1lhFcBzwMvAP4x463jOopeq8p3kDv5GPF6r9C60rg+Yh4G3BR\n",
       "/+/zfmBnp+OO45i9pwFfyczrgDuBFfmS2YWbF3z+G8CyfSMcd6yPd8HMipaZ9wIvRsSNwBe73jOK\n",
       "iLiE3p/vNxnzvaMJeTdwD71wfLrjLaPaBdyUmZcB2yLi1K4HLSYzn8zMG4AX6F37MNs/NAOs72zY\n",
       "IhbuzcwXMvOe/lnrpcAdHc87roWbI+L7gZuBG5dzw7hjfeSCGVj8gpkVJSJOB74APJCZf9n1nhFd\n",
       "Dvw4cAVwZUSc0fGeYZ4ADvf/WYLDXY8Z0SkcPaM+DLylwy1LMQscuTZ/il6wV7SI+HngGuAjmflC\n",
       "13tG8AF6fbsN+JGI+LXl+EXH/Zh1uQtmImI/cA69bzSvZeZHul00uoi4AngpM+/qessgEbEF+D3g\n",
       "OeDvM/OvOp40VEScDdxK727uo5n5xx1PGioi7s3MiyPiGuA8eg/x7crMFfkNMiLuBT5B7x7iV+j1\n",
       "6EuZeXenwwaIiPsy88MLPr83My/ucpMkSZIkSZIkSZIkSZIkSZIknaz+F0bomzA95AKFAAAAAElF\n",
       "TkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c0aa8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snow days  104\n",
      "Trace snow:  37\n",
      "0-2 in snow:  44\n",
      "2-4 in snow:  9\n",
      "4-8 in snow:  6\n",
      "8-15 in snow:  6\n",
      "+15 in snow:  2\n"
     ]
    }
   ],
   "source": [
    "days_with_snow=snow_daily[snow_daily['snow']==1]\n",
    "\n",
    "\n",
    "plt.hist(days_with_snow['snow_fall'].values,bins=10)\n",
    "plt.xlim([0,15])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print 'Snow days ',len(days_with_snow)\n",
    "print 'Trace snow: ',len(days_with_snow[days_with_snow['snow_fall']==0])\n",
    "print '0-2 in snow: ',len(days_with_snow[(days_with_snow['snow_fall']>0)&(days_with_snow['snow_fall']<=2)])\n",
    "print '2-4 in snow: ',len(days_with_snow[(days_with_snow['snow_fall']>2)&(days_with_snow['snow_fall']<=4)])\n",
    "print '4-8 in snow: ',len(days_with_snow[(days_with_snow['snow_fall']>4)&(days_with_snow['snow_fall']<=8)])\n",
    "print '8-15 in snow: ',len(days_with_snow[(days_with_snow['snow_fall']>8)&(days_with_snow['snow_fall']<=15)])\n",
    "print '+15 in snow: ',len(days_with_snow[(days_with_snow['snow_fall']>15)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stationid</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1002</td>\n",
       "      <td> 42.329550</td>\n",
       "      <td>-71.056960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1004</td>\n",
       "      <td> 42.321438</td>\n",
       "      <td>-71.052393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 1005</td>\n",
       "      <td> 42.274816</td>\n",
       "      <td>-71.029176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1006</td>\n",
       "      <td> 42.265615</td>\n",
       "      <td>-71.019402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 1007</td>\n",
       "      <td> 42.250879</td>\n",
       "      <td>-71.004798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stationid        lat        lon\n",
       "0       1002  42.329550 -71.056960\n",
       "1       1004  42.321438 -71.052393\n",
       "2       1005  42.274816 -71.029176\n",
       "3       1006  42.265615 -71.019402\n",
       "4       1007  42.250879 -71.004798"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_info=pd.read_csv('../../../data/Stations_clean.csv')\n",
    "station_latlong=pd.read_csv('../../../data/stations_latlong.csv')\n",
    "station_latlong=station_latlong[['stationid','lat','lon']]\n",
    "\n",
    "station_latlong.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>stationid</th>\n",
       "      <th>name</th>\n",
       "      <th>line_temp</th>\n",
       "      <th>grouping</th>\n",
       "      <th>dist_to_center</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 0</td>\n",
       "      <td> 1002</td>\n",
       "      <td> Andrew Square</td>\n",
       "      <td> Red</td>\n",
       "      <td> 2</td>\n",
       "      <td>  3.404767</td>\n",
       "      <td> 42.329550</td>\n",
       "      <td>-71.056960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 1</td>\n",
       "      <td> 1004</td>\n",
       "      <td>    JFK/U Mass</td>\n",
       "      <td> Red</td>\n",
       "      <td> 0</td>\n",
       "      <td>  4.328881</td>\n",
       "      <td> 42.321438</td>\n",
       "      <td>-71.052393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2</td>\n",
       "      <td> 1005</td>\n",
       "      <td>  North Quincy</td>\n",
       "      <td> Red</td>\n",
       "      <td> 1</td>\n",
       "      <td>  9.777437</td>\n",
       "      <td> 42.274816</td>\n",
       "      <td>-71.029176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 3</td>\n",
       "      <td> 1006</td>\n",
       "      <td>     Wollaston</td>\n",
       "      <td> Red</td>\n",
       "      <td> 1</td>\n",
       "      <td> 10.976943</td>\n",
       "      <td> 42.265615</td>\n",
       "      <td>-71.019402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 4</td>\n",
       "      <td> 1007</td>\n",
       "      <td> Quincy Center</td>\n",
       "      <td> Red</td>\n",
       "      <td> 1</td>\n",
       "      <td> 12.909591</td>\n",
       "      <td> 42.250879</td>\n",
       "      <td>-71.004798</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  stationid           name line_temp  grouping  dist_to_center  \\\n",
       "0           0       1002  Andrew Square       Red         2        3.404767   \n",
       "1           1       1004     JFK/U Mass       Red         0        4.328881   \n",
       "2           2       1005   North Quincy       Red         1        9.777437   \n",
       "3           3       1006      Wollaston       Red         1       10.976943   \n",
       "4           4       1007  Quincy Center       Red         1       12.909591   \n",
       "\n",
       "         lat        lon  \n",
       "0  42.329550 -71.056960  \n",
       "1  42.321438 -71.052393  \n",
       "2  42.274816 -71.029176  \n",
       "3  42.265615 -71.019402  \n",
       "4  42.250879 -71.004798  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_info=station_info.merge(station_latlong,on='stationid')\n",
    "station_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "station_id: station id of interest\n",
    "bins: a list of tuples except for the first and last elements which are singletons. Used for identifying snowfall levels\n",
    "    For example, bins=[ (0), (0,2), (2,4)..., (15)  ]\n",
    "    \n",
    "'''\n",
    "\n",
    "def subset(station_id,bins,begin_time=5.25,end_time=24):\n",
    "    \n",
    "    res={}\n",
    "    \n",
    "    #get subset of station\n",
    "    station_records=gate_1315[gate_1315['locationid']==station_id]\n",
    "    \n",
    "    #want to subset the dataframe to only include months in which there may be snow\n",
    "    # don't want the seasonal trends of Summer, Spring, early Fall to skew my values for when there \n",
    "    # is no snow\n",
    "    station_records=station_records[(station_records['month']>=10) |(station_records['month']<=3)]\n",
    "    station_records=station_records[station_records['weekday']<5]\n",
    "    station_records=station_records[(station_records['servicetime_fraction']<=end_time) & (station_records['servicetime_fraction']>=begin_time) ]\n",
    "    \n",
    "    # Now merge in the weather data\n",
    "    station_records=station_records.merge(snow_daily,left_on='servicedate',right_on='service_day')\n",
    "    #return station_records\n",
    "\n",
    "    #get subset of snow records\n",
    "    no_snow=station_records[station_records['snow']==False]\n",
    "    #print mean_ridership\n",
    "    \n",
    "    snow=station_records[station_records['snow']==True]  \n",
    "    no_snow_mean=no_snow[['entries','servicetime_fraction']].groupby(['servicetime_fraction']).agg(np.mean)\n",
    "    \n",
    "    res['station_id']=1.*station_id\n",
    "    res['station_name']= station_info[station_info['stationid']==station_id]['name'].values[0]\n",
    "    res['coords']= [station_info[station_info['stationid']==station_id]['lat'].values[0],station_info[station_info['stationid']==station_id]['lon'].values[0]]\n",
    "    \n",
    "    res['time_intervals']=list(no_snow_mean.index.values)\n",
    "\n",
    "    #print len(res['time_intervals'])\n",
    "    res['mean_ent']=list(no_snow_mean['entries'].values)\n",
    "    res['aggr_ent']=np.sum(list(no_snow_mean['entries'].values))\n",
    "\n",
    "    \n",
    "    # create time series for various snow bins\n",
    "    res['mean_ent_snow']={}\n",
    "    res['aggr_ent_snow']={}\n",
    "    \n",
    "    # create time series for the first, singleton element in bins\n",
    "    snow_subset=snow[snow['snow_fall']==bins[0]]\n",
    "    snow_subset=snow_subset[['entries','servicetime_fraction']].groupby(['servicetime_fraction']).agg(np.mean)\n",
    "    #print len(snow_subset)\n",
    "    res['mean_ent_snow'][str(bins[0])]=list(1.*snow_subset['entries'].values)\n",
    "    res['aggr_ent_snow'][str(bins[0])]=np.sum(list((1.*snow_subset['entries']).values))\n",
    "    \n",
    "    for i in range(1,len(bins)-1):\n",
    "        snow_subset=snow[(snow['snow_fall']>bins[i][0])&(snow['snow_fall']<=bins[i][1])]\n",
    "        snow_subset=snow_subset[['entries','servicetime_fraction']].groupby(['servicetime_fraction']).agg(np.mean)\n",
    "        #print len(snow_subset)\n",
    "        res['mean_ent_snow'][str(bins[i][0])+'_'+str(bins[i][1])]=list(1.*snow_subset['entries'].values)\n",
    "        res['aggr_ent_snow'][str(bins[i][0])+'_'+str(bins[i][1])]=np.sum(list(1.*snow_subset['entries'].values))\n",
    "\n",
    "        \n",
    "    # create time series for the last, singleton element in bins\n",
    "    snow_subset=snow[snow['snow_fall']>=bins[-1]]\n",
    "    snow_subset=snow_subset[['entries','servicetime_fraction']].groupby(['servicetime_fraction']).agg(np.mean)\n",
    "    #print len(snow_subset)\n",
    "    res['mean_ent_snow'][str(bins[(-1)])]=list(1.*snow_subset['entries'].values)\n",
    "    res['aggr_ent_snow'][str(bins[(-1)])]=np.sum(list(1.*snow_subset['entries'].values))\n",
    "\n",
    "        \n",
    "    \n",
    "    return res\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t=subset(1009,bins=[ (0), (0,2),(4,8),(8,15),(15)] ,begin_time=5.25,end_time=24)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing master list containing series for each station\n",
    "\n",
    "Note: station_id is stored as a float due to serializable issues in json.dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "master_list=list([])\n",
    "\n",
    "station_ids=list(station_info['stationid'].unique())\n",
    "bins_=[ (0), (0,2),(4,8),(8,15),(15)]\n",
    "\n",
    "## keys in master dict have to be strings in order to be compatible with json.dump()\n",
    "for station in station_ids:\n",
    "    master_list.append(subset(station,bins= bins_ ,begin_time=5.25,end_time=24))\n",
    "    \n",
    "print len(master_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write actual json file\n",
    "filename='station_series.json'\n",
    "\n",
    "with open(filename, 'w') as outfile:\n",
    "    json.dump(master_list, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1002.0"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(filename) as data_file:    \n",
    "    data = json.load(data_file)\n",
    "    \n",
    "data[0]['station_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write shorter, summary json file \n",
    "\n",
    "This json file will be the same as the above one except the series 'mean_ent_snow','mean_ent', and 'time_intervals' will be removed. Wanted to have both available just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summary_list=list([])\n",
    "\n",
    "station_ids=list(station_info['stationid'].unique())\n",
    "bins_=[ (0), (0,2),(4,8),(8,15),(15)]\n",
    "remove=['mean_ent_snow','mean_ent','time_intervals']\n",
    "\n",
    "## keys in master dict have to be strings in order to be compatible with json.dump()\n",
    "for station in station_ids:\n",
    "    t=subset(station,bins= bins_ ,begin_time=5.25,end_time=24)\n",
    "    \n",
    "    for key in remove:\n",
    "        t.pop(key,None)\n",
    "        \n",
    "    summary_list.append(t)\n",
    "    \n",
    "print len(summary_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write actual json file\n",
    "filename='station_summary.json'\n",
    "\n",
    "with open(filename, 'w') as outfile:\n",
    "    json.dump(summary_list, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'aggr_ent': 6010.281460552052,\n",
       " u'aggr_ent_snow': {u'0': 6025.081196581196,\n",
       "  u'0_2': 5606.535349388798,\n",
       "  u'15': 3153.0,\n",
       "  u'4_8': 4524.666666666666,\n",
       "  u'8_15': 3771.4833333333336},\n",
       " u'coords': [42.32955, -71.05696],\n",
       " u'station_id': 1002.0,\n",
       " u'station_name': u'Andrew Square'}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(filename) as data_file:    \n",
    "    data = json.load(data_file)\n",
    "    \n",
    "data[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
